{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import tarfile\n",
    "import argparse\n",
    "from transformers import Swinv2ForImageClassification, AutoImageProcessor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    CenterCrop,\n",
    "    ToTensor,\n",
    "    Normalize,\n",
    "    Lambda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_serialized(checkpoint_path, serialized_file):\n",
    "    # Instantiate model architecture and load the saved state_dict\n",
    "    model = Swinv2ForImageClassification.from_pretrained(checkpoint_path)\n",
    "    state_dict = torch.load(serialized_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_dummy_input(checkpoint_path):\n",
    "    # Derive dummy input tensor shape from the image processor config\n",
    "    image_processor = AutoImageProcessor.from_pretrained(checkpoint_path)\n",
    "    if \"shortest_edge\" in image_processor.size:\n",
    "        size = image_processor.size[\"shortest_edge\"]\n",
    "    elif \"height\" in image_processor.size and \"width\" in image_processor.size:\n",
    "        s = image_processor.size\n",
    "        size = (s[\"height\"], s[\"width\"])\n",
    "    else:\n",
    "        size = 224  # default\n",
    "    dummy_input = (\n",
    "        torch.randn(1, 3, size, size)\n",
    "        if isinstance(size, int)\n",
    "        else torch.randn(1, 3, size[0], size[1])\n",
    "    )\n",
    "    return dummy_input\n",
    "\n",
    "\n",
    "def load_test_image(checkpoint_path, test_file):\n",
    "    # Create a transform similar to ModelEvaluator and load a test image\n",
    "    image_processor = AutoImageProcessor.from_pretrained(checkpoint_path)\n",
    "    if \"shortest_edge\" in image_processor.size:\n",
    "        size = image_processor.size[\"shortest_edge\"]\n",
    "    else:\n",
    "        size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "    normalize = (\n",
    "        Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "        if hasattr(image_processor, \"image_mean\")\n",
    "        and hasattr(image_processor, \"image_std\")\n",
    "        else Lambda(lambda x: x)\n",
    "    )\n",
    "    transform = Compose(\n",
    "        [\n",
    "            Resize(size),\n",
    "            CenterCrop(size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "    image = Image.open(test_file).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "\n",
    "def validate_serialized_file(\n",
    "    checkpoint_path, serialized_file, test_file=None, index_to_class=None\n",
    "):\n",
    "    model = load_model_from_serialized(checkpoint_path, serialized_file)\n",
    "    if test_file:\n",
    "        input_tensor = load_test_image(checkpoint_path, test_file)\n",
    "    else:\n",
    "        input_tensor = get_dummy_input(checkpoint_path)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "    print(\"Inference output:\", outputs)\n",
    "    # Compute predicted indices from logits.\n",
    "    preds = torch.argmax(outputs.logits, dim=1)\n",
    "    if index_to_class:\n",
    "        import json\n",
    "\n",
    "        with open(index_to_class, \"r\") as f:\n",
    "            mapping = json.load(f)\n",
    "        # Convert predicted index to class name using the mapping.\n",
    "        pred_classes = [\n",
    "            mapping.get(str(int(idx)), f\"Class {int(idx)}\") for idx in preds\n",
    "        ]\n",
    "        print(\"Predicted classes:\", pred_classes)\n",
    "    else:\n",
    "        print(\"Predicted class indices:\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mar_file(mar_file):\n",
    "    try:\n",
    "        with tarfile.open(mar_file, \"r\") as tar:\n",
    "            members = tar.getnames()\n",
    "            if \"MAR-INF/manifest.json\" not in members:\n",
    "                print(\"ERROR: 'MAR-INF/manifest.json' not found in the MAR file.\")\n",
    "                return False\n",
    "            manifest_member = tar.getmember(\"MAR-INF/manifest.json\")\n",
    "            with tar.extractfile(manifest_member) as f:\n",
    "                manifest = json.load(f)\n",
    "            print(\"Manifest loaded successfully:\")\n",
    "            print(json.dumps(manifest, indent=4))\n",
    "            # Check for required keys in manifest. Adjust keys as needed.\n",
    "            required_keys = [\"model\", \"serializedFile\", \"handler\"]\n",
    "            missing_keys = [key for key in required_keys if key not in manifest]\n",
    "            if missing_keys:\n",
    "                print(\"Missing keys in manifest:\", missing_keys)\n",
    "                return False\n",
    "            print(\"All required keys are present in the manifest.\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(\"Failed to validate MAR file:\", e)\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Validate exported serialized model file by running inference.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint_path\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to the model checkpoint or config directory.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--serialized_file\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to the exported serialized model file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test_file\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Path to a test image file to run inference.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--index_to_class\",\n",
    "        type=str,\n",
    "        default=None,\n",
    "        help=\"Path to the index_to_class.json file.\",\n",
    "    )\n",
    "    parser.add_argument(\"--mar_file\", type=str, help=\"Path to the MAR file.\")\n",
    "\n",
    "    print(\"Test args\")\n",
    "    argarr = [\n",
    "        \"--checkpoint_path ../environments/torchserve/gpu/artifacts\",\n",
    "        \"--serialized_file ../environments/torchserve/gpu/artifacts/27spp_model_1_serialized.pt\",\n",
    "        \"--test_file ../environments/torchserve/gpu/artifacts/solanum_nigrum.tiff\",\n",
    "        \"--index_to_class ../environments/torchserve/gpu/artifacts/index_to_name.json\",\n",
    "        \"--mar_file ../environments/torchserve/gpu/artifacts/27spp_model_1.mar\"\n",
    "    ]\n",
    "    argstr = \" \".join(argarr)\n",
    "\n",
    "    print(\"Parsing args\")\n",
    "    args = parser.parse_args(argstr.split())\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    validate_serialized_file(\n",
    "        args.checkpoint_path, args.serialized_file, args.test_file, args.index_to_class\n",
    "    )\n",
    "\n",
    "    if args.mar_file:\n",
    "        validate_mar_file(args.mar_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
